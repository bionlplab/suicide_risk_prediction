{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049928c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Use physical GPU 1\n",
    "import math, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, get_scheduler\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name()}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3953e7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration class and utility functions\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    save_path: str = \"roberta_mean_pool_fold_{}.pt\"  # For 5fold model naming\n",
    "    roberta_name: str = \"roberta-base\"\n",
    "    max_length: int = 256\n",
    "    batch_size: int = 8            # batch = groups; each group has 5 posts internally\n",
    "    epochs: int = 20\n",
    "    lr_head: float = 1e-3\n",
    "    lr_backbone: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.06\n",
    "    unfreeze_last_n_layers: int = 3   # 0=freeze all; e.g., 3=unfreeze last 3 layers\n",
    "    seed: int = 42\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    num_workers: int = 2\n",
    "    pin_memory: bool = True\n",
    "    data_csv: str = \"data_with_instance_and_fold_labels.csv\"  # Updated to new data file\n",
    "    pooling_type: str = \"mean\"   # Only use mean pooling\n",
    "\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(\"Configuration class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading function\n",
    "def load_dataframe(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load and validate dataframe\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    required_cols = [\"post_sequence\", \"suicide_risk\", \"post_created_utc\", \"fold_label\"]\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise KeyError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Keep required columns and rename text column\n",
    "    df = df[required_cols].rename(columns={\"post_sequence\": \"text\"})\n",
    "    \n",
    "    # Convert timestamp\n",
    "    df[\"post_created_utc\"] = pd.to_datetime(df[\"post_created_utc\"])\n",
    "    \n",
    "    # Basic validation\n",
    "    if len(df) % 5 != 0:\n",
    "        raise ValueError(f\"Row count {len(df)} is not a multiple of 5. Ensure original order is not shuffled.\")\n",
    "    \n",
    "    # Ensure every 5 rows have the same label\n",
    "    G = len(df) // 5\n",
    "    for g in range(G):\n",
    "        labs = df.iloc[g*5:(g+1)*5][\"suicide_risk\"].tolist()\n",
    "        if len(set(labs)) != 1:\n",
    "            raise ValueError(f\"Group {g} has inconsistent labels: {labs}\")\n",
    "    \n",
    "    # Force labels to int\n",
    "    df[\"suicide_risk\"] = df[\"suicide_risk\"].astype(int)\n",
    "    df[\"fold_label\"] = df[\"fold_label\"].astype(int)\n",
    "    return df\n",
    "\n",
    "print(\"Data loading function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce3970",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Calculate relative time intervals (in hours)\n",
    "        time_intervals = []\n",
    "        off = 0\n",
    "        for size in sizes:\n",
    "            group_timestamps = flat_timestamps[off:off+size]\n",
    "            # Calculate hour difference for each timestamp relative to the first timestamp\n",
    "            base_time = group_timestamps[0]\n",
    "            intervals = [(ts - base_time).total_seconds() / 3600 for ts in group_timestamps]\n",
    "            time_intervals.extend(intervals)\n",
    "            off += size\n",
    "        \n",
    "        return enc, labels, torch.tensor(sizes, dtype=torch.long), torch.tensor(time_intervals, dtype=torch.float32)\n",
    "\n",
    "print(\"Dataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling implementation\n",
    "\n",
    "class MeanPooling(nn.Module):\n",
    "    \"\"\"Mean pooling\"\"\"\n",
    "    def __init__(self, hidden_size=768):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, cls_batch: torch.Tensor, group_sizes: torch.Tensor, time_intervals: torch.Tensor = None):\n",
    "        # MeanPooling doesn't use time information, maintaining backward compatibility\n",
    "        out, off = [], 0\n",
    "        for k in group_sizes.tolist():\n",
    "            out.append(cls_batch[off:off+k].mean(dim=0, keepdim=True))\n",
    "            off += k\n",
    "        return torch.cat(out, dim=0)\n",
    "\n",
    "print(\"Mean Pooling defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f1206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RoBERTa Mean Pooling classifier\n",
    "class RobertaEnhancedPoolClassifier(nn.Module):\n",
    "    def __init__(self, roberta_name=\"roberta-base\", num_classes=4, pooling_type=\"mean\"):\n",
    "        super().__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(roberta_name)\n",
    "        hidden = self.backbone.config.hidden_size  # 768 for roberta-base\n",
    "        self.pooling_type = pooling_type\n",
    "        \n",
    "        # Only support mean pooling\n",
    "        if pooling_type == \"mean\":\n",
    "            self.pooling = MeanPooling(hidden)\n",
    "        else:\n",
    "            raise ValueError(f\"Only mean pooling is supported, but got: {pooling_type}\")\n",
    "            \n",
    "        # 768→128→16→4\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(hidden, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "    \n",
    "    def forward(self, encodings, group_sizes: torch.Tensor, time_intervals: torch.Tensor = None):\n",
    "        out = self.backbone(input_ids=encodings[\"input_ids\"], attention_mask=encodings[\"attention_mask\"])\n",
    "        cls = out.last_hidden_state[:, 0, :]  # (B*5, 768)\n",
    "        \n",
    "        # Use mean pooling\n",
    "        pooled = self.pooling(cls, group_sizes, time_intervals)  # (B, 768)\n",
    "        \n",
    "        return self.head(pooled)  # (B, num_classes)\n",
    "\n",
    "def set_backbone_trainable(model: RobertaEnhancedPoolClassifier, unfreeze_last_n_layers: int = 0):\n",
    "    \"\"\"Control the number of trainable backbone layers\"\"\"\n",
    "    # First freeze all parameters\n",
    "    for p in model.backbone.parameters(): \n",
    "        p.requires_grad = False\n",
    "    \n",
    "    # Unfreeze last n layers\n",
    "    if unfreeze_last_n_layers > 0:\n",
    "        encoder_layers = model.backbone.encoder.layer  # RobertaEncoder\n",
    "        for layer in encoder_layers[-unfreeze_last_n_layers:]:\n",
    "            for p in layer.parameters(): \n",
    "                p.requires_grad = True\n",
    "\n",
    "print(\"Classifier model defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ddf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training-related utility functions\n",
    "def compute_class_weights(y: np.ndarray, num_classes: int) -> torch.Tensor:\n",
    "    \"\"\"Compute class weights to handle imbalanced data\"\"\"\n",
    "    classes = np.arange(num_classes)\n",
    "    w = compute_class_weight(class_weight=\"balanced\", classes=classes, y=y)\n",
    "    return torch.tensor(w, dtype=torch.float32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, criterion=None) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    model.eval()\n",
    "    all_logits, all_labels, total_loss, n = [], [], 0.0, 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        if len(batch) == 4:  # New format: includes time information\n",
    "            enc, labels, sizes, time_intervals = batch\n",
    "            time_intervals = time_intervals.to(device)\n",
    "        else:  # Old format: backward compatibility\n",
    "            enc, labels, sizes = batch\n",
    "            time_intervals = None\n",
    "            \n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "        labels = labels.to(device)\n",
    "        sizes = sizes.to(device)\n",
    "        \n",
    "        logits = model(enc, sizes, time_intervals)\n",
    "        all_logits.append(logits.detach().cpu())\n",
    "        all_labels.append(labels.detach().cpu())\n",
    "        \n",
    "        if criterion is not None:\n",
    "            total_loss += criterion(logits, labels).item() * labels.size(0)\n",
    "            n += labels.size(0)\n",
    "    \n",
    "    logits = torch.cat(all_logits)\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_pred = logits.argmax(dim=1).numpy()\n",
    "    \n",
    "    wf1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    out = {\"weighted_f1\": float(wf1)}\n",
    "    if criterion is not None and n > 0: \n",
    "        out[\"loss\"] = float(total_loss / n)\n",
    "    return out\n",
    "\n",
    "print(\"Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e779794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5fold cross-validation training function\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_single_fold(df: pd.DataFrame, cfg: TrainConfig, fold_idx: int, num_classes: int = 4) -> Dict[str, any]:\n",
    "    \"\"\"Train model for a single fold\"\"\"\n",
    "    set_seed(cfg.seed)\n",
    "    device = cfg.device\n",
    "    print(f\"Training fold {fold_idx}, using device: {device}\")\n",
    "    \n",
    "    # Split data based on fold_label\n",
    "    G = len(df) // 5\n",
    "    group_ids = np.arange(G)\n",
    "    \n",
    "    # Get fold labels for each group (take fold_label from first row of each group)\n",
    "    group_fold_labels = np.array([int(df.iloc[g*5][\"fold_label\"]) for g in group_ids], dtype=int)\n",
    "    group_labels = np.array([int(df.iloc[g*5][\"suicide_risk\"]) for g in group_ids], dtype=int)\n",
    "    \n",
    "    # Current fold as validation set, other 4 folds as training set\n",
    "    g_tr = group_ids[group_fold_labels != fold_idx]\n",
    "    g_val = group_ids[group_fold_labels == fold_idx]\n",
    "    y_tr = group_labels[group_fold_labels != fold_idx]\n",
    "    y_val = group_labels[group_fold_labels == fold_idx]\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Training set {len(g_tr)} groups, validation set {len(g_val)} groups\")\n",
    "    print(f\"Training set label distribution: {np.bincount(y_tr)}\")\n",
    "    print(f\"Validation set label distribution: {np.bincount(y_val)}\")\n",
    "    \n",
    "    # Create tokenizer and data loaders\n",
    "    tok = AutoTokenizer.from_pretrained(cfg.roberta_name)\n",
    "    collate = Collator(tok, max_length=cfg.max_length)\n",
    "    \n",
    "    ds_tr = GroupedTextDataset(df, g_tr)\n",
    "    ds_val = GroupedTextDataset(df, g_val)\n",
    "    \n",
    "    dl_tr = DataLoader(ds_tr, batch_size=cfg.batch_size, shuffle=True, \n",
    "                       num_workers=cfg.num_workers, pin_memory=cfg.pin_memory, collate_fn=collate)\n",
    "    dl_val = DataLoader(ds_val, batch_size=cfg.batch_size, shuffle=False, \n",
    "                        num_workers=cfg.num_workers, pin_memory=cfg.pin_memory, collate_fn=collate)\n",
    "    \n",
    "    # Create model\n",
    "    model = RobertaEnhancedPoolClassifier(cfg.roberta_name, num_classes=num_classes, \n",
    "                                        pooling_type=cfg.pooling_type).to(device)\n",
    "    set_backbone_trainable(model, cfg.unfreeze_last_n_layers)\n",
    "    \n",
    "    # Set up optimizer\n",
    "    params = []\n",
    "    if any(p.requires_grad for p in model.backbone.parameters()):\n",
    "        params.append({\"params\": [p for p in model.backbone.parameters() if p.requires_grad],\n",
    "                       \"lr\": cfg.lr_backbone, \"weight_decay\": cfg.weight_decay})\n",
    "    params.append({\"params\": list(model.head.parameters()), \"lr\": cfg.lr_head, \"weight_decay\": cfg.weight_decay})\n",
    "    params.append({\"params\": list(model.pooling.parameters()), \"lr\": cfg.lr_head, \"weight_decay\": cfg.weight_decay})\n",
    "    \n",
    "    opt = optim.AdamW(params)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    steps_per_epoch = max(1, math.ceil(len(ds_tr) / cfg.batch_size))\n",
    "    total_steps = cfg.epochs * steps_per_epoch\n",
    "    warmup_steps = int(cfg.warmup_ratio * total_steps)\n",
    "    \n",
    "    sch = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=warmup_steps,\n",
    "        num_training_steps=total_steps,\n",
    "    )\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_w = compute_class_weights(y_tr, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_w)\n",
    "    \n",
    "    # Training loop\n",
    "    best_f1, best_state, patience, bad = -1.0, None, 5, 0\n",
    "    \n",
    "    print(f\"Starting training for Fold {fold_idx}...\")\n",
    "    for ep in tqdm(range(1, cfg.epochs+1), desc=f\"Fold {fold_idx} Training\"):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        n_batches = 0\n",
    "        \n",
    "        for batch in dl_tr:\n",
    "            if len(batch) == 4:\n",
    "                enc, labels, sizes, time_intervals = batch\n",
    "                time_intervals = time_intervals.to(device)\n",
    "            else:\n",
    "                enc, labels, sizes = batch\n",
    "                time_intervals = None\n",
    "                \n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            labels = labels.to(device)\n",
    "            sizes = sizes.to(device)\n",
    "            \n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(enc, sizes, time_intervals)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            sch.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            n_batches += 1\n",
    "        \n",
    "        # Evaluate each epoch\n",
    "        tr_eval = evaluate(model, dl_tr, device, criterion)\n",
    "        val_eval = evaluate(model, dl_val, device, criterion)\n",
    "        \n",
    "        if ep % 5 == 0:  # Print every 5 epochs\n",
    "            print(f\"  Epoch {ep:02d} | Train Loss {tr_eval['loss']:.4f} WF1 {tr_eval['weighted_f1']:.4f} | \"\n",
    "                  f\"Val Loss {val_eval['loss']:.4f} WF1 {val_eval['weighted_f1']:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_eval[\"weighted_f1\"] > best_f1 + 1e-6:\n",
    "            best_f1 = val_eval[\"weighted_f1\"]\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            bad = 0\n",
    "        else:\n",
    "            bad += 1\n",
    "            if bad >= patience:\n",
    "                print(f\"  Early stopping at epoch {ep} (best Val WF1={best_f1:.4f})\")\n",
    "                break\n",
    "    \n",
    "    # Save best model\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state, strict=True)\n",
    "        model_save_path = cfg.save_path.format(fold_idx)\n",
    "        torch.save(best_state, model_save_path)\n",
    "        print(f\"  Model saved to: {model_save_path}\")\n",
    "    \n",
    "    # Validation set evaluation and generate classification report\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl_val:\n",
    "            if len(batch) == 4:\n",
    "                enc, labels, sizes, time_intervals = batch\n",
    "                time_intervals = time_intervals.to(device)\n",
    "            else:\n",
    "                enc, labels, sizes = batch\n",
    "                time_intervals = None\n",
    "                \n",
    "            enc = {k: v.to(device) for k, v in enc.items()}\n",
    "            labels = labels.to(device)\n",
    "            sizes = sizes.to(device)\n",
    "            \n",
    "            logits = model(enc, sizes, time_intervals)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Generate classification report\n",
    "    report = classification_report(all_labels, all_preds, \n",
    "                                 target_names=['class_0', 'class_1', 'class_2', 'class_3'],\n",
    "                                 digits=4)\n",
    "    print(f\"\\nFold {fold_idx} validation set classification report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        \"fold_idx\": fold_idx,\n",
    "        \"best_f1\": best_f1,\n",
    "        \"model_path\": model_save_path,\n",
    "        \"val_predictions\": all_preds,\n",
    "        \"val_labels\": all_labels,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "print(\"5fold training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a229008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting prediction function\n",
    "def ensemble_predict(test_df: pd.DataFrame, cfg: TrainConfig, voting_strategy: str = \"hard\", num_classes: int = 4):\n",
    "    \"\"\"\n",
    "    Use 5 trained models for ensemble prediction\n",
    "    \n",
    "    Args:\n",
    "        test_df: Test data\n",
    "        cfg: Configuration\n",
    "        voting_strategy: \"hard\" or \"soft\"\n",
    "        num_classes: Number of classes\n",
    "    \n",
    "    Returns:\n",
    "        Prediction results and probabilities\n",
    "    \"\"\"\n",
    "    device = cfg.device\n",
    "    tok = AutoTokenizer.from_pretrained(cfg.roberta_name)\n",
    "    collate = Collator(tok, max_length=cfg.max_length)\n",
    "    \n",
    "    # Prepare test data\n",
    "    G_test = len(test_df) // 5\n",
    "    test_group_ids = np.arange(G_test)\n",
    "    ds_test = GroupedTextDataset(test_df, test_group_ids)\n",
    "    dl_test = DataLoader(ds_test, batch_size=cfg.batch_size, shuffle=False, \n",
    "                        num_workers=cfg.num_workers, pin_memory=cfg.pin_memory, collate_fn=collate)\n",
    "    \n",
    "    # Load 5 models and make predictions\n",
    "    all_predictions = []  # Store predictions from each model\n",
    "    all_probabilities = []  # Store probabilities from each model\n",
    "    \n",
    "    for fold_idx in range(5):\n",
    "        model_path = cfg.save_path.format(fold_idx)\n",
    "        print(f\"Loading model: {model_path}\")\n",
    "        \n",
    "        # Create and load model\n",
    "        model = RobertaEnhancedPoolClassifier(cfg.roberta_name, num_classes=num_classes, \n",
    "                                            pooling_type=cfg.pooling_type).to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        \n",
    "        fold_preds = []\n",
    "        fold_probs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dl_test:\n",
    "                if len(batch) == 4:\n",
    "                    enc, labels, sizes, time_intervals = batch\n",
    "                    time_intervals = time_intervals.to(device)\n",
    "                else:\n",
    "                    enc, labels, sizes = batch\n",
    "                    time_intervals = None\n",
    "                    \n",
    "                enc = {k: v.to(device) for k, v in enc.items()}\n",
    "                sizes = sizes.to(device)\n",
    "                \n",
    "                logits = model(enc, sizes, time_intervals)\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "                preds = logits.argmax(dim=1)\n",
    "                \n",
    "                fold_preds.extend(preds.cpu().numpy())\n",
    "                fold_probs.extend(probs.cpu().numpy())\n",
    "        \n",
    "        all_predictions.append(fold_preds)\n",
    "        all_probabilities.append(fold_probs)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)  # (5, n_samples)\n",
    "    all_probabilities = np.array(all_probabilities)  # (5, n_samples, n_classes)\n",
    "    \n",
    "    # Generate final predictions based on voting strategy\n",
    "    if voting_strategy == \"hard\":\n",
    "        # Hard voting: choose the most frequent class\n",
    "        final_predictions = []\n",
    "        for i in range(all_predictions.shape[1]):\n",
    "            votes = all_predictions[:, i]\n",
    "            # Count votes for each class\n",
    "            vote_counts = np.bincount(votes, minlength=num_classes)\n",
    "            final_pred = np.argmax(vote_counts)\n",
    "            final_predictions.append(final_pred)\n",
    "        final_predictions = np.array(final_predictions)\n",
    "        final_probabilities = None\n",
    "        \n",
    "    elif voting_strategy == \"soft\":\n",
    "        # Soft voting: average probabilities\n",
    "        final_probabilities = np.mean(all_probabilities, axis=0)  # (n_samples, n_classes)\n",
    "        final_predictions = np.argmax(final_probabilities, axis=1)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown voting strategy: {voting_strategy}. Choose 'hard' or 'soft'.\")\n",
    "    \n",
    "    print(f\"Completed prediction using {voting_strategy} voting strategy\")\n",
    "    print(f\"Prediction result distribution: {np.bincount(final_predictions)}\")\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": final_predictions,\n",
    "        \"probabilities\": final_probabilities,\n",
    "        \"individual_predictions\": all_predictions,\n",
    "        \"individual_probabilities\": all_probabilities,\n",
    "        \"voting_strategy\": voting_strategy\n",
    "    }\n",
    "\n",
    "print(\"Voting prediction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86964b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and basic configuration\n",
    "data_file = \"data_with_instance_and_fold_labels.csv\"\n",
    "\n",
    "try:\n",
    "    df = load_dataframe(data_file)\n",
    "    print(f\"Data loaded successfully!\")\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    print(f\"Total groups: {len(df) // 5}\")\n",
    "    print(f\"\\nLabel distribution:\")\n",
    "    print(df['suicide_risk'].value_counts().sort_index())\n",
    "    print(f\"\\nFold distribution:\")\n",
    "    # Get fold labels for each group\n",
    "    G = len(df) // 5\n",
    "    group_fold_labels = [df.iloc[g*5][\"fold_label\"] for g in range(G)]\n",
    "    fold_counts = pd.Series(group_fold_labels).value_counts().sort_index()\n",
    "    print(fold_counts)\n",
    "    print(f\"\\nFirst few rows of data:\")\n",
    "    print(df[['text', 'suicide_risk', 'fold_label']].head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file '{data_file}' not found\")\n",
    "    print(\"Please ensure the data file is in the current directory\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac29771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 0 training\n",
    "cfg = TrainConfig(\n",
    "    save_path=\"bio_mean_pool_fold_{}.pt\",\n",
    "    roberta_name=\"/prj0129/jzh4027/IEEE/local_models/models--microsoft--BiomedNLP-BiomedBERT-base-uncased-abstract/snapshots/d673b8835373c6fa116d6d8006b33d48734e305d\",\n",
    "    max_length=512,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    lr_head=1e-3,\n",
    "    lr_backbone=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.06,\n",
    "    unfreeze_last_n_layers=3,\n",
    "    seed=42,\n",
    "    data_csv=\"data_with_instance_and_fold_labels.csv\",\n",
    "    pooling_type=\"mean\"\n",
    ")\n",
    "\n",
    "print(f\"Configuration completed! Starting training for Fold 0\")\n",
    "print(f\"Device: {cfg.device}\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    fold_0_result = train_single_fold(df, cfg, fold_idx=0, num_classes=4)\n",
    "    print(f\"\\nFold 0 training completed! Best validation F1: {fold_0_result['best_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"Error: Data not loaded. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822a6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 1 training\n",
    "if 'df' in locals():\n",
    "    fold_1_result = train_single_fold(df, cfg, fold_idx=1, num_classes=4)\n",
    "    print(f\"\\nFold 1 training completed! Best validation F1: {fold_1_result['best_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"Error: Data not loaded. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 2 training\n",
    "if 'df' in locals():\n",
    "    fold_2_result = train_single_fold(df, cfg, fold_idx=2, num_classes=4)\n",
    "    print(f\"\\nFold 2 training completed! Best validation F1: {fold_2_result['best_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"Error: Data not loaded. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 3 training\n",
    "if 'df' in locals():\n",
    "    fold_3_result = train_single_fold(df, cfg, fold_idx=3, num_classes=4)\n",
    "    print(f\"\\nFold 3 training completed! Best validation F1: {fold_3_result['best_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"Error: Data not loaded. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249dbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold 4 training\n",
    "if 'df' in locals():\n",
    "    fold_4_result = train_single_fold(df, cfg, fold_idx=4, num_classes=4)\n",
    "    print(f\"\\nFold 4 training completed! Best validation F1: {fold_4_result['best_f1']:.4f}\")\n",
    "else:\n",
    "    print(\"Error: Data not loaded. Please run the data loading cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914d4b60",
   "metadata": {},
   "source": [
    "# Ensemble Prediction on Test Set\n",
    "\n",
    "Now we'll load all 5 trained models and perform ensemble prediction using hard voting on the test set (`sdoh_evaluate_on_leaderboard.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05263d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataframe(file_path, max_length=256):\n",
    "    \"\"\"\n",
    "    Load test dataframe for prediction (without suicide_risk and fold_label columns)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check required columns for test set - using actual column names\n",
    "    required_cols = ['user_id', 'post_created_utc', 'post_sequence']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    print(f\"Loaded test dataframe: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Rename columns to match training data format\n",
    "    df = df.rename(columns={\n",
    "        'post_created_utc': 'posting_time', \n",
    "        'post_sequence': 'posting_text'\n",
    "    })\n",
    "    \n",
    "    # Basic validation - must be multiple of 5\n",
    "    if len(df) % 5 != 0:\n",
    "        raise ValueError(f\"Row count {len(df)} is not a multiple of 5. Each group should have exactly 5 rows.\")\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")  # Use same tokenizer as training\n",
    "    \n",
    "    def tokenize_text(text):\n",
    "        if pd.isna(text):\n",
    "            text = \"\"\n",
    "        return tokenizer(str(text), \n",
    "                        max_length=max_length, \n",
    "                        padding='max_length', \n",
    "                        truncation=True, \n",
    "                        return_tensors='pt')\n",
    "    \n",
    "    print(\"Tokenizing test texts...\")\n",
    "    df['tokenized'] = df['posting_text'].apply(tokenize_text)\n",
    "    \n",
    "    # Convert posting_time to datetime\n",
    "    df['posting_time'] = pd.to_datetime(df['posting_time'])\n",
    "    \n",
    "    # Group every 5 consecutive rows (just like training data)\n",
    "    grouped_data = []\n",
    "    total_groups = len(df) // 5\n",
    "    \n",
    "    for g in range(total_groups):\n",
    "        start_idx = g * 5\n",
    "        end_idx = start_idx + 5\n",
    "        group = df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # Sort by posting_time within each group\n",
    "        group_sorted = group.sort_values('posting_time')\n",
    "        grouped_data.append(group_sorted)\n",
    "    \n",
    "    print(f\"Total instances (groups): {len(grouped_data)}\")\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f63d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(grouped_data):\n",
    "    \"\"\"\n",
    "    Create dataset for test prediction\n",
    "    \"\"\"\n",
    "    test_data = []\n",
    "    \n",
    "    for group in grouped_data:\n",
    "        # Extract tokenized inputs\n",
    "        input_ids = torch.stack([row['tokenized']['input_ids'].squeeze(0) for _, row in group.iterrows()])\n",
    "        attention_mask = torch.stack([row['tokenized']['attention_mask'].squeeze(0) for _, row in group.iterrows()])\n",
    "        \n",
    "        # Calculate time intervals (even though not used by MeanPooling)\n",
    "        times = group['posting_time'].tolist()\n",
    "        time_intervals = []\n",
    "        for i in range(len(times)):\n",
    "            if i == 0:\n",
    "                time_intervals.append(0)\n",
    "            else:\n",
    "                interval = (times[i] - times[i-1]).total_seconds() / 3600  # hours\n",
    "                time_intervals.append(interval)\n",
    "        \n",
    "        test_data.append({\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'time_intervals': torch.tensor(time_intervals, dtype=torch.float32),\n",
    "            'group_id': len(test_data)  # Just use the group index as identifier\n",
    "        })\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be72780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(test_data, model_paths, device='cuda', voting_strategy='hard'):\n",
    "    \"\"\"\n",
    "    Perform ensemble prediction using hard or soft voting\n",
    "    \n",
    "    Args:\n",
    "        test_data: Test data\n",
    "        model_paths: List of model file paths\n",
    "        device: Device to use for inference\n",
    "        voting_strategy: 'hard' for majority voting, 'soft' for probability averaging\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (ensemble_predictions, individual_predictions, individual_probabilities)\n",
    "    \"\"\"\n",
    "    models = []\n",
    "    \n",
    "    # Load all models\n",
    "    print(\"Loading trained models...\")\n",
    "    for i, model_path in enumerate(model_paths):\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        \n",
    "        # Initialize model\n",
    "        model = RobertaEnhancedPoolClassifier(\n",
    "            roberta_name=\"roberta-base\",  # Use same as training\n",
    "            num_classes=4,\n",
    "            pooling_type=\"mean\"\n",
    "        )\n",
    "        \n",
    "        # Load state dict\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        models.append(model)\n",
    "        print(f\"Model {i} loaded successfully\")\n",
    "    \n",
    "    print(f\"\\nTotal models loaded: {len(models)}\")\n",
    "    \n",
    "    # Perform predictions\n",
    "    all_predictions = []  # List of arrays, each array contains predictions from one model\n",
    "    all_probabilities = []  # List of arrays, each array contains probabilities from one model\n",
    "    \n",
    "    print(\"Making predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for model_idx, model in enumerate(models):\n",
    "            print(f\"Predicting with model {model_idx}...\")\n",
    "            model_predictions = []\n",
    "            model_probabilities = []\n",
    "            \n",
    "            for batch in test_data:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                time_intervals = batch['time_intervals'].to(device)\n",
    "                \n",
    "                # Prepare encodings dict and group sizes\n",
    "                encodings = {\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask\n",
    "                }\n",
    "                group_sizes = torch.tensor([len(input_ids)], dtype=torch.long).to(device)\n",
    "                \n",
    "                # Get prediction and probabilities\n",
    "                outputs = model(encodings, group_sizes, time_intervals)\n",
    "                probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]  # Get probabilities for single instance\n",
    "                predicted_class = torch.argmax(outputs, dim=1).cpu().item()\n",
    "                \n",
    "                model_predictions.append(predicted_class)\n",
    "                model_probabilities.append(probabilities)\n",
    "            \n",
    "            all_predictions.append(model_predictions)\n",
    "            all_probabilities.append(model_probabilities)\n",
    "            print(f\"Model {model_idx} predictions: {len(model_predictions)} instances\")\n",
    "    \n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    all_predictions = np.array(all_predictions)  # Shape: (5_models, n_instances)\n",
    "    all_probabilities = np.array(all_probabilities)  # Shape: (5_models, n_instances, 4_classes)\n",
    "    \n",
    "    # Ensemble prediction based on strategy\n",
    "    if voting_strategy.lower() == 'hard':\n",
    "        print(f\"\\nPerforming hard voting ensemble...\")\n",
    "        ensemble_predictions = []\n",
    "        \n",
    "        for i in range(len(test_data)):\n",
    "            # Get predictions from all models for instance i\n",
    "            votes = all_predictions[:, i]  # Get votes from all 5 models for instance i\n",
    "            \n",
    "            # Count votes for each class\n",
    "            vote_counts = np.bincount(votes, minlength=4)\n",
    "            \n",
    "            # Get majority vote (in case of tie, argmax returns the first occurrence)\n",
    "            majority_vote = np.argmax(vote_counts)\n",
    "            ensemble_predictions.append(majority_vote)\n",
    "            \n",
    "        ensemble_predictions = np.array(ensemble_predictions)\n",
    "        ensemble_probabilities = None\n",
    "        \n",
    "    elif voting_strategy.lower() == 'soft':\n",
    "        print(f\"\\nPerforming soft voting ensemble...\")\n",
    "        # Average probabilities across all models\n",
    "        ensemble_probabilities = np.mean(all_probabilities, axis=0)  # Shape: (n_instances, 4_classes)\n",
    "        \n",
    "        # Get final predictions from averaged probabilities\n",
    "        ensemble_predictions = np.argmax(ensemble_probabilities, axis=1)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown voting strategy: {voting_strategy}. Choose 'hard' or 'soft'.\")\n",
    "    \n",
    "    print(f\"Ensemble predictions completed using {voting_strategy} voting: {len(ensemble_predictions)} instances\")\n",
    "    \n",
    "    # Print prediction distribution\n",
    "    pred_counts = np.bincount(ensemble_predictions, minlength=4)\n",
    "    print(f\"Prediction distribution:\")\n",
    "    for class_id in range(4):\n",
    "        percentage = pred_counts[class_id] / len(ensemble_predictions) * 100\n",
    "        print(f\"  Class {class_id}: {pred_counts[class_id]} instances ({percentage:.1f}%)\")\n",
    "    \n",
    "    return ensemble_predictions, all_predictions, all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b37379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"Loading test dataset...\")\n",
    "test_file_path = \"sdoh_evaluate_on_leaderboard.csv\"\n",
    "test_grouped_data = load_test_dataframe(test_file_path)\n",
    "\n",
    "# Create test dataset\n",
    "print(\"\\nCreating test dataset...\")\n",
    "test_data = create_test_dataset(test_grouped_data)\n",
    "print(f\"Test dataset created: {len(test_data)} instances\")\n",
    "\n",
    "# Define model paths\n",
    "model_paths = [\n",
    "    \"roberta_mean_pool_fold_0.pt\",\n",
    "    \"roberta_mean_pool_fold_1.pt\", \n",
    "    \"roberta_mean_pool_fold_2.pt\",\n",
    "    \"roberta_mean_pool_fold_3.pt\",\n",
    "    \"roberta_mean_pool_fold_4.pt\"\n",
    "]\n",
    "\n",
    "# Check if all model files exist\n",
    "print(\"\\nChecking model files...\")\n",
    "for path in model_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"✓ {path} exists\")\n",
    "    else:\n",
    "        print(f\"✗ {path} not found!\")\n",
    "        raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Perform ensemble prediction - you can change voting_strategy to 'soft' for soft voting\n",
    "voting_strategy = 'soft'  # Change to 'soft' for soft voting\n",
    "print(f\"\\nStarting ensemble prediction with {voting_strategy} voting...\")\n",
    "ensemble_predictions, individual_predictions, individual_probabilities = ensemble_predict(\n",
    "    test_data, model_paths, device, voting_strategy=voting_strategy\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"ENSEMBLE PREDICTION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total test instances: {len(ensemble_predictions)}\")\n",
    "print(f\"Voting strategy: {voting_strategy.upper()}\")\n",
    "print(f\"Ensemble predictions: {ensemble_predictions}\")\n",
    "\n",
    "# Show some individual model predictions for comparison\n",
    "print(f\"\\nIndividual model predictions (first 10 instances):\")\n",
    "print(\"Instance | Model0 | Model1 | Model2 | Model3 | Model4 | Ensemble\")\n",
    "print(\"-\" * 65)\n",
    "for i in range(min(10, len(ensemble_predictions))):\n",
    "    individual_preds = [individual_predictions[j][i] for j in range(5)]\n",
    "    print(f\"{i:8d} | {individual_preds[0]:6d} | {individual_preds[1]:6d} | {individual_preds[2]:6d} | {individual_preds[3]:6d} | {individual_preds[4]:6d} | {ensemble_predictions[i]:8d}\")\n",
    "\n",
    "# If soft voting, show some probability information\n",
    "if voting_strategy.lower() == 'soft' and individual_probabilities is not None:\n",
    "    print(f\"\\nSoft voting - Average probabilities (first 5 instances):\")\n",
    "    print(\"Instance |   Class 0   |   Class 1   |   Class 2   |   Class 3   | Prediction\")\n",
    "    print(\"-\" * 75)\n",
    "    avg_probs = np.mean(individual_probabilities, axis=0)  # Average across models\n",
    "    for i in range(min(5, len(ensemble_predictions))):\n",
    "        probs = avg_probs[i]\n",
    "        print(f\"{i:8d} | {probs[0]:10.4f} | {probs[1]:10.4f} | {probs[2]:10.4f} | {probs[3]:10.4f} | {ensemble_predictions[i]:10d}\")\n",
    "\n",
    "print(f\"\\nFinal ensemble predictions array:\")\n",
    "print(ensemble_predictions)\n",
    "\n",
    "# Save predictions to npy file\n",
    "np.save('ensemble_predictions.npy', ensemble_predictions)\n",
    "print(f\"\\nPredictions saved to: ensemble_predictions.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f08aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('5fold_bio.npy', ensemble_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
